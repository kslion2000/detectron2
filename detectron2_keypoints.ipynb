{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"detectron2_keypoints.ipynb","provenance":[],"authorship_tag":"ABX9TyMLY8q5hry1iEON+J6/cqbr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PK9VjcGkxVsz"},"source":["Use Drtectron2 to detect human keypoint."]},{"cell_type":"code","metadata":{"id":"WRoKxxe6wroH"},"source":["# install the requirements of detectron\n","!pip install pyyaml==5.1 pycocotools>=2.0.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFy17q8LxD3s"},"source":["#install detectron2\n","assert torch.__version__.startswith(\"1.6\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-KljZC0x9HU"},"source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import os, json, cv2, random\n","import numpy as np\n","import csv\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NLWaGScCycjj"},"source":["Extracting human keyponts and painting them on origin image."]},{"cell_type":"code","metadata":{"id":"_L6ny77uyCtj"},"source":["im = cv2.imread(\"https://www.bomb01.com/upload/news/original/0ffd961a53f39e8a9ce68e73da1fbd90.jpg\")\n","cfg = get_cfg()   # get a fresh new config\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","outputs = predictor(im)\n","predictions = outputs[\"instances\"].to(\"cpu\")\n","\n","v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_j_3spqWzs17"},"source":["Extracting human keyponts and making them as new images."]},{"cell_type":"code","metadata":{"id":"HjAGaAjN0XL-"},"source":["im = cv2.imread(\"https://www.bomb01.com/upload/news/original/0ffd961a53f39e8a9ce68e73da1fbd90.jpg\")\n","s = im.shape\n","img = np.zeros(s, np.uint8)\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","outputs = predictor(im)\n","outputs[\"instances\"].remove(\"pred_boxes\")\n","predictions = outputs[\"instances\"].to(\"cpu\")\n","\n","v = Visualizer(img[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = v.draw_instance_predictions(predictions)\n","cv2_imshow(im)\n","cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q0I8TiFk1jJY"},"source":["Using keypoints to make a human skeleton image."]},{"cell_type":"code","metadata":{"id":"cXOwcnhK1i0V"},"source":["im = cv2.imread(\"https://www.bomb01.com/upload/news/original/0ffd961a53f39e8a9ce68e73da1fbd90.jpg\")\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","outputs = predictor(im)\n","outputs[\"instances\"].remove(\"pred_boxes\")\n","predictions = outputs[\"instances\"].to(\"cpu\")\n","keypoints = predictions.pred_keypoints\n","cv2_imshow(im)\n","\n","x_point = []\n","y_point = []\n","for i in keypoints[0]:\n","  x_point.append(float(i[0]))\n","  y_point.append(float(i[1]))\n","x = [[x_point[0],x_point[1]], [x_point[0],x_point[2]], [x_point[1],x_point[3]], [x_point[2],x_point[4]], [x_point[5],x_point[6]], [x_point[5],x_point[7]], [x_point[7],x_point[9]], [x_point[6],x_point[8]], [x_point[8],x_point[10]], [x_point[11],x_point[12]], [x_point[11],x_point[13]], [x_point[13],x_point[15]], [x_point[12],x_point[14]], [x_point[14],x_point[16]], [x_point[0],(x_point[5]+x_point[6])/2], [(x_point[5]+x_point[6])/2,(x_point[11]+x_point[12])/2]]\n","y = [[y_point[0],y_point[1]], [y_point[0],y_point[2]], [y_point[1],y_point[3]], [y_point[2],y_point[4]], [y_point[5],y_point[6]], [y_point[5],y_point[7]], [y_point[7],y_point[9]], [y_point[6],y_point[8]], [y_point[8],y_point[10]], [y_point[11],y_point[12]], [y_point[11],y_point[13]], [y_point[13],y_point[15]], [y_point[12],y_point[14]], [y_point[14],y_point[16]], [y_point[0],(y_point[5]+y_point[6])/2], [(y_point[5]+y_point[6])/2,(y_point[11]+y_point[12])/2]]\n","\n","color = [\"b\",\"b\",\"b\",\"b\",\"y\",\"darkorange\",\"papayawhip\",\"darkorange\",\"papayawhip\",\"y\",\"green\",\"aqua\",\"green\",\"aqua\",\"r\",\"r\"]\n","for i in range(len(x)):\n","  plt.plot(x[i], y[i], color=color[i])\n","  plt.scatter(x[i], y[i], color=\"k\")\n","\n","plt.gca().invert_yaxis()\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]}]}